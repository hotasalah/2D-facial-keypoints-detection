{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing facial key points detection\n",
    "This task is considerd as a regression problem, where the prediction isn't a single value, but several continuous outputs. <br>The objective is to detect the key points present on an image of a face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchsummary import summary\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and importing the relevant data. that contains images and their corresponding facial key points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'P1_Facial_Keypoints'...\n",
      "Updating files:   0% (46/5805)\n",
      "Updating files:   1% (59/5805)\n",
      "Updating files:   1% (85/5805)\n",
      "Updating files:   2% (117/5805)\n",
      "Updating files:   2% (162/5805)\n",
      "Updating files:   3% (175/5805)\n",
      "Updating files:   4% (233/5805)\n",
      "Updating files:   4% (265/5805)\n",
      "Updating files:   5% (291/5805)\n",
      "Updating files:   6% (349/5805)\n",
      "Updating files:   6% (376/5805)\n",
      "Updating files:   7% (407/5805)\n",
      "Updating files:   8% (465/5805)\n",
      "Updating files:   8% (498/5805)\n",
      "Updating files:   9% (523/5805)\n",
      "Updating files:   9% (544/5805)\n",
      "Updating files:  10% (581/5805)\n",
      "Updating files:  11% (639/5805)\n",
      "Updating files:  11% (641/5805)\n",
      "Updating files:  12% (697/5805)\n",
      "Updating files:  13% (755/5805)\n",
      "Updating files:  13% (758/5805)\n",
      "Updating files:  14% (813/5805)\n",
      "Updating files:  14% (861/5805)\n",
      "Updating files:  15% (871/5805)\n",
      "Updating files:  16% (929/5805)\n",
      "Updating files:  16% (936/5805)\n",
      "Updating files:  17% (987/5805)\n",
      "Updating files:  17% (991/5805)\n",
      "Updating files:  17% (1023/5805)\n",
      "Updating files:  18% (1045/5805)\n",
      "Updating files:  19% (1103/5805)\n",
      "Updating files:  19% (1113/5805)\n",
      "Updating files:  20% (1161/5805)\n",
      "Updating files:  20% (1171/5805)\n",
      "Updating files:  20% (1208/5805)\n",
      "Updating files:  21% (1220/5805)\n",
      "Updating files:  21% (1263/5805)\n",
      "Updating files:  22% (1278/5805)\n",
      "Updating files:  22% (1289/5805)\n",
      "Updating files:  23% (1336/5805)\n",
      "Updating files:  23% (1369/5805)\n",
      "Updating files:  24% (1394/5805)\n",
      "Updating files:  24% (1404/5805)\n",
      "Updating files:  25% (1452/5805)\n",
      "Updating files:  25% (1461/5805)\n",
      "Updating files:  26% (1510/5805)\n",
      "Updating files:  26% (1521/5805)\n",
      "Updating files:  27% (1568/5805)\n",
      "Updating files:  27% (1585/5805)\n",
      "Updating files:  27% (1608/5805)\n",
      "Updating files:  28% (1626/5805)\n",
      "Updating files:  29% (1684/5805)\n",
      "Updating files:  29% (1696/5805)\n",
      "Updating files:  30% (1742/5805)\n",
      "Updating files:  30% (1749/5805)\n",
      "Updating files:  30% (1799/5805)\n",
      "Updating files:  31% (1800/5805)\n",
      "Updating files:  32% (1858/5805)\n",
      "Updating files:  32% (1880/5805)\n",
      "Updating files:  32% (1895/5805)\n",
      "Updating files:  32% (1907/5805)\n",
      "Updating files:  33% (1916/5805)\n",
      "Updating files:  33% (1972/5805)\n",
      "Updating files:  34% (1974/5805)\n",
      "Updating files:  35% (2032/5805)\n",
      "Updating files:  35% (2040/5805)\n",
      "Updating files:  36% (2090/5805)\n",
      "Updating files:  36% (2120/5805)\n",
      "Updating files:  37% (2148/5805)\n",
      "Updating files:  37% (2169/5805)\n",
      "Updating files:  38% (2206/5805)\n",
      "Updating files:  38% (2227/5805)\n",
      "Updating files:  39% (2264/5805)\n",
      "Updating files:  39% (2309/5805)\n",
      "Updating files:  40% (2322/5805)\n",
      "Updating files:  41% (2381/5805)\n",
      "Updating files:  41% (2408/5805)\n",
      "Updating files:  41% (2432/5805)\n",
      "Updating files:  42% (2439/5805)\n",
      "Updating files:  42% (2480/5805)\n",
      "Updating files:  43% (2497/5805)\n",
      "Updating files:  44% (2555/5805)\n",
      "Updating files:  44% (2570/5805)\n",
      "Updating files:  44% (2605/5805)\n",
      "Updating files:  45% (2613/5805)\n",
      "Updating files:  45% (2660/5805)\n",
      "Updating files:  46% (2671/5805)\n",
      "Updating files:  46% (2727/5805)\n",
      "Updating files:  47% (2729/5805)\n",
      "Updating files:  48% (2787/5805)\n",
      "Updating files:  48% (2820/5805)\n",
      "Updating files:  49% (2845/5805)\n",
      "Updating files:  50% (2903/5805)\n",
      "Updating files:  50% (2928/5805)\n",
      "Updating files:  51% (2961/5805)\n",
      "Updating files:  51% (2994/5805)\n",
      "Updating files:  52% (3019/5805)\n",
      "Updating files:  52% (3073/5805)\n",
      "Updating files:  53% (3077/5805)\n",
      "Updating files:  53% (3110/5805)\n",
      "Updating files:  53% (3130/5805)\n",
      "Updating files:  54% (3135/5805)\n",
      "Updating files:  54% (3143/5805)\n",
      "Updating files:  54% (3177/5805)\n",
      "Updating files:  55% (3193/5805)\n",
      "Updating files:  55% (3212/5805)\n",
      "Updating files:  55% (3221/5805)\n",
      "Updating files:  55% (3239/5805)\n",
      "Updating files:  56% (3251/5805)\n",
      "Updating files:  56% (3261/5805)\n",
      "Updating files:  56% (3273/5805)\n",
      "Updating files:  57% (3309/5805)\n",
      "Updating files:  57% (3336/5805)\n",
      "Updating files:  58% (3367/5805)\n",
      "Updating files:  59% (3425/5805)\n",
      "Updating files:  60% (3483/5805)\n",
      "Updating files:  61% (3542/5805)\n",
      "Updating files:  61% (3571/5805)\n",
      "Updating files:  62% (3600/5805)\n",
      "Updating files:  63% (3658/5805)\n",
      "Updating files:  63% (3673/5805)\n",
      "Updating files:  64% (3716/5805)\n",
      "Updating files:  64% (3732/5805)\n",
      "Updating files:  64% (3769/5805)\n",
      "Updating files:  65% (3774/5805)\n",
      "Updating files:  66% (3832/5805)\n",
      "Updating files:  66% (3848/5805)\n",
      "Updating files:  67% (3890/5805)\n",
      "Updating files:  67% (3922/5805)\n",
      "Updating files:  68% (3948/5805)\n",
      "Updating files:  68% (3993/5805)\n",
      "Updating files:  69% (4006/5805)\n",
      "Updating files:  69% (4055/5805)\n",
      "Updating files:  70% (4064/5805)\n",
      "Updating files:  71% (4122/5805)\n",
      "Updating files:  71% (4128/5805)\n",
      "Updating files:  71% (4164/5805)\n",
      "Updating files:  72% (4180/5805)\n",
      "Updating files:  73% (4238/5805)\n",
      "Updating files:  73% (4242/5805)\n",
      "Updating files:  73% (4267/5805)\n",
      "Updating files:  74% (4296/5805)\n",
      "Updating files:  74% (4325/5805)\n",
      "Updating files:  75% (4354/5805)\n",
      "Updating files:  75% (4369/5805)\n",
      "Updating files:  75% (4400/5805)\n",
      "Updating files:  76% (4412/5805)\n",
      "Updating files:  76% (4446/5805)\n",
      "Updating files:  77% (4470/5805)\n",
      "Updating files:  78% (4528/5805)\n",
      "Updating files:  78% (4547/5805)\n",
      "Updating files:  78% (4577/5805)\n",
      "Updating files:  79% (4586/5805)\n",
      "Updating files:  79% (4640/5805)\n",
      "Updating files:  80% (4644/5805)\n",
      "Updating files:  81% (4703/5805)\n",
      "Updating files:  81% (4706/5805)\n",
      "Updating files:  82% (4761/5805)\n",
      "Updating files:  83% (4819/5805)\n",
      "Updating files:  83% (4868/5805)\n",
      "Updating files:  84% (4877/5805)\n",
      "Updating files:  85% (4935/5805)\n",
      "Updating files:  86% (4993/5805)\n",
      "Updating files:  86% (5036/5805)\n",
      "Updating files:  87% (5051/5805)\n",
      "Updating files:  88% (5109/5805)\n",
      "Updating files:  89% (5167/5805)\n",
      "Updating files:  89% (5196/5805)\n",
      "Updating files:  90% (5225/5805)\n",
      "Updating files:  90% (5263/5805)\n",
      "Updating files:  91% (5283/5805)\n",
      "Updating files:  91% (5294/5805)\n",
      "Updating files:  92% (5341/5805)\n",
      "Updating files:  92% (5367/5805)\n",
      "Updating files:  93% (5399/5805)\n",
      "Updating files:  93% (5422/5805)\n",
      "Updating files:  94% (5457/5805)\n",
      "Updating files:  95% (5515/5805)\n",
      "Updating files:  95% (5521/5805)\n",
      "Updating files:  96% (5573/5805)\n",
      "Updating files:  97% (5631/5805)\n",
      "Updating files:  97% (5636/5805)\n",
      "Updating files:  98% (5689/5805)\n",
      "Updating files:  98% (5714/5805)\n",
      "Updating files:  99% (5747/5805)\n",
      "Updating files:  99% (5786/5805)\n",
      "Updating files:  99% (5796/5805)\n",
      "Updating files:  99% (5803/5805)\n",
      "Updating files: 100% (5805/5805)\n",
      "Updating files: 100% (5805/5805), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/udacity/P1_Facial_Keypoints.git\n",
    "!cd P1_Facial_Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'P1_Facial_Keypoints/data/training/'\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*.jpg'))\n",
    "\n",
    "data = pd.read_csv('P1_Facial_Keypoints/data/training_frames_keypoints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the FacesData class, that provides input and output data points for the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacesData(Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \n",
    "        super(FacesData).__init__()\n",
    "        self.df = df\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        \n",
    "        img_path = 'P1_Facial_Keypoints/data/training/' + self.df.iloc[ix,0]\n",
    "        img = cv2.imread(img_path) / 255.0\n",
    "        \n",
    "        kp = deepcopy(self.df.iloc[ix,1:].tolist())\n",
    "        kp_x = (np.array(kp[0::2])/img.shape[1]).tolist()\n",
    "        kp_y = (np.array(kp[1::2])/img.shape[0]).tolist()\n",
    "        kp2 = kp_x + kp_y\n",
    "        kp2 = torch.tensor(kp2)\n",
    "        \n",
    "        img = self.preprocess_input(img)\n",
    "        \n",
    "        return img, kp2\n",
    "    \n",
    "    def preprocess_input(self, img):\n",
    "        \n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "        img = self.normalize(img).float()\n",
    "        \n",
    "        return img.to(device)\n",
    "    \n",
    "    def load_img(self, ix):\n",
    "        \n",
    "        img_path = 'P1_Facial_Keypoints/data/training/' + self.df.iloc[ix,0]        \n",
    "        img = cv2.imread(img_path)\n",
    "        img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255.\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a training and test data split, and establish training and test datasets and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=101)\n",
    "\n",
    "train_dataset = FacesData(train.reset_index(drop=True))\n",
    "test_dataset = FacesData(test.reset_index(drop=True))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    model = models.vgg16(pretrained=True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    model.avgpool = nn.Sequential(nn.Conv2d(512,512,3),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Flatten())\n",
    "    \n",
    "    model.classifier = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.5),\n",
    "                                     nn.Linear(512, 136),\n",
    "                                     nn.Sigmoid())\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    return model.to(device), criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\hp/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec054dd07526434fab4ec9593abac789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:01<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, criterion, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions to train on a batch of data points and also to validate on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(img, kps, model, optimizer, criterion):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    _kps = model(img.to(device))\n",
    "    loss = criterion(_kps, kps.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function that returns the loss on test data and the predicted key points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_batch(img, kps, model, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    _kps = model(img.to(device))\n",
    "    loss = criterion(_kps, kps.to(device))\n",
    "    \n",
    "    return _kps, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model based on training the data loader and test it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 1 : 50\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss = [], []\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\" epoch {epoch+ 1} : 50\")\n",
    "    epoch_train_loss, epoch_test_loss = 0, 0\n",
    "    \n",
    "    for ix, (img,kps) in enumerate(train_loader):\n",
    "        loss = train_batch(img, kps, model, optimizer, criterion)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    epoch_train_loss /= (ix+1)\n",
    "\n",
    "    for ix,(img,kps) in enumerate(test_loader):\n",
    "        ps, loss = validate_batch(img, kps, model, criterion)\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "    epoch_test_loss /= (ix+1)\n",
    "\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    test_loss.append(epoch_test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting the training and test loss over increasing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(50)+1\n",
    "\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, test_loss, 'r', label='Test loss')\n",
    "\n",
    "plt.title('Training and Test loss over increasing epochs')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model on a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 0\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "\n",
    "plt.title('Original image')\n",
    "\n",
    "im = test_dataset.load_img(ix)\n",
    "plt.imshow(im)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.subplot(222)\n",
    "\n",
    "plt.title('Image with facial keypoints')\n",
    "\n",
    "x, _ = test_dataset[ix]\n",
    "plt.imshow(im)\n",
    "\n",
    "kp = model(x[None]).flatten().detach().cpu()\n",
    "\n",
    "plt.scatter(kp[:68]*224, kp[68:]*224, c='r')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
